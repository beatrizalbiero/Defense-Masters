\begin{frame}{Conclusões}

\begin{itemize}
    \item<1->A acurácia máxima atingida pelo modelo foi de 17\% considerando todos os verbos do corpus ($73/423$). 
    \item<2->O tamanho do corpus é provavelmente incompatível com a arquitetura do modelo.
    \item<3->Ocorreram 32 erros de super-regularização.
    \item<4->A acurácia pode não ser uma boa métrica para este experimento, pois não captura o número de traços fonéticos previstos corretamente.
\end{itemize}


\end{frame}

\begin{frame}{Sugestões para Trabalhos Futuros}

\begin{itemize}
    \item<1-> Aumentar o corpus. 
    \item<2-> Tentar modelos de atenção (Transformers).
    \item<3-> Realizar testes psicolinguísticos.
\end{itemize}

\end{frame}

\begin{frame}{Aprendizados}

\begin{itemize}
    \item<1->Python
    \item<2->Fonética e Teorias de Aquisição
    \item<3->Aprendizado de Máquina e Ciência de Dados
    \item<4->Pesquisa

\end{itemize}

\end{frame}

\begin{frame}{Contribuições}

\begin{itemize}
    \item<1->Corpus 
    \item<2->Resultados dos Experimentos
    \item<3->Divulgação Científica:
    \begin{itemize}
        \item<4->IV Workshop do GLIC 2017 (oral)
        \item<5->ENAPOL XXI \& XXII (2018 e 2019)(oral)
        \item<6->PROPOR 2018 (pôster)
        \item<7->Khipu AI 2019 (pôster)
    \end{itemize}
\end{itemize}

\end{frame}
